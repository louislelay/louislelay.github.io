<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Louis Le Lay - Personal Website</title>
    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        display: flex;
    }

    #sidebar {
        width: 20%;
        background-color: #333;
        color: white;
        padding: 1%;
        display: flex;
        flex-direction: column;
        align-items: flex-start;
        white-space: nowrap;
        position: fixed;
        height: 100vh;
        overflow-y: auto;
        transition: transform 0.3s ease-in-out;
    }

    #sidebar a {
        color: white !important;
        text-decoration: none;
        padding: 2% 5%;
        display: inline-block;
    }

    #sidebar a:hover {
        background-color: #575757;
    }

    #content {
        flex-grow: 1;
        display: flex;
        flex-direction: column;
        min-height: 100vh;
        transition: transform 0.3s ease-in-out;
        margin-left: 25%;
        margin-right: 10%;
    }

    .section {
        display: none;
        flex-direction: column;
        justify-content: space-between;
        padding-top: 3%;
    }

    .active {
        display: block;
        flex-direction: column;
        justify-content: space-between;
        padding-top: 3%;
    }
    a {
        color: blue !important;
        text-decoration: none;
    }

    .date {
        margin-top: 5%;
        font-weight: bold;
    }

    .repo {
        margin-left: 5%;
        font-weight: bold;
    }

    .pr {
        margin-left: 10%;
    }

    .spacer {
        flex-grow: 1;
    }

    .contact-links a {
        color: blue;
        text-decoration: none;
        margin-right: 3%;
    }
    
    .project-video {
        height: 30vh;
        width: 55vh;
        /* max-width: 100%; */
        /* object-fit: contain; */
        /* display: block; */
        /* margin: 0 auto 1em auto; */
        margin-bottom: 1em;
        display: none;
    }

    .image-gallery {
        margin-top: 1em;
        text-align: center; /* Example styling */
        }

    .project-image {
        height: 30vh;
        width: auto;
        /* max-width: 90%; */
        margin-bottom: 1em;
    }

    .experience h2 {
        font-size: 1.8rem;
        color: #333;
    }

    .experience .location {
        font-size: 1rem;
        color: #777;
    }

    .experience .dates {
        font-size: 0.9rem;
        color: #555;
    }

    .experience .responsibilities {
        list-style-type: disc;
        padding-left: 20px;
    }

    .experience .responsibilities li {
        margin-bottom: 5px;
    }

    button.prev,
    button.next {
        background-color: #444;
        color: white;
        border: none;
        padding: 6px 10px;
        margin: 0 5px;
        cursor: pointer;
    }

    button.prev:hover,
    button.next:hover {
        background-color: #666;
    }

    #menu-button {
        display: none;
        background-color: #333;
        color: white;
        border: none;
        padding: 10px 15px;
        font-size: 16px;
        position: fixed;
        top: 10px;
        left: 10px;
        cursor: pointer;
    }

    @media (max-width: 768px) {
        #sidebar {
            transform: translateX(-100%);
            width: 60%;
        }
        
        #sidebar.show {
            transform: translateX(0);
        }

        #menu-button {
            display: block;
        }

        /* #content {
            margin-left: 10%;
        } */
    }

    </style>
</head>
<body>
    <button id="menu-button" onclick="toggleSidebar()">‚ò∞ Menu</button>
    <div id="sidebar">
        <h2>Louis Le Lay</h2>
        <a href="#about" onclick="showSection('about'); closeSidebar();">About Me</a>
        <a href="#background" onclick="showSection('background'); closeSidebar();">Background</a>
        <a href="#projects" onclick="showSection('projects'); closeSidebar();">Projects</a>
        <a href="#opensource" onclick="showSection('opensource'); closeSidebar();">Open Source Contributions</a>
    </div>
    <div id="content">
    <!-- About Me Section -->
    <div id="about" class="section active">
        <h1>About Louis Le Lay</h1>
        <p> Robotics engineering student with hands-on contributions to open-source simulation frameworks, sim-to-real 
            reinforcement learning pipelines, and multi-sensor fusion in ROS 2. Comfortable with C++/Python,
            real-time control, and modern DevOps. Seeking to work where advanced simulation and AI
            methods drive practical robotic capabilities.
        </p>
        <h3>üîß Core Skills</h3>
        <ul>
            <li><strong>Programming & Tools:</strong> C++, Python, ROS, ROS2, Git, Docker, Gazebo, Mujoco, IsaacSim, IsaacLab, PyBullet, MATLAB</li>
            <li><strong>Core Competencies:</strong> Sensor Fusion, SLAM, VR Simulation, Machine Learning, Reinforcement Learning, Sim2Real Transfer, Control Systems</li>
        </ul>
        <h3>üì© Contact</h3>
        <p class="contact-links">
            <a href="mailto:le.lay.louis@gmail.com">Email</a> |
            <a href="https://www.linkedin.com/in/louis-le-lay/">LinkedIn</a> |
            <a href="https://github.com/louislelay">GitHub</a>
        </p>
    </div>

    <!-- Background Section -->
    <div id="background" class="section">
        <h1>Background</h1>

        <h2>üíº Experience</h2>

        <section class="experience">
            <header>
                <h3>Robotics Software Developer ‚Äì Naova (RoboCup Team)</h3>
                <p class="location">
                Montreal, Canada <span class="dates">(Nov 2024 ‚Äì Present)</span>
                </p>
            </header>
            <ul class="responsibilities">
                <li>Worked on walking control and referee signals perception.</li>
            </ul>
        </section>


        <section class="experience">
            <header>
                <h3>Robotics Research Engineer Intern ‚Äì Real World Robot Informatics Lab, University of Tokyo</h3>
                <p class="location">
                Tokyo, Japan <span class="dates">(Jun 2024 ‚Äì Aug 2024)</span>
                </p>
            </header>
            <ul class="responsibilities">
                <li>Worked on sensor fusion for 3D-LiDAR and RGB-D camera to enhance GO1 robot perception.</li>
            </ul>
        </section>

        <section class="experience">
            <header>
                <h3>Robotics Engineer Student (Industry Collaboration Project) ‚Äì AIRBUS</h3>
                <p class="location">
                Paris, France <span class="dates">(Sept 2023 - June 2024)</span>
                </p>
            </header>
            <ul class="responsibilities">
                <li>Developed A320 cockpit automation POC, targeting a 13% production time cut and 2026 factory implementation.</li>
            </ul>
        </section>

        <section class="experience">
            <header>
                <h3>Robotics Software Developer ‚Äì Robotech</h3>
                <p class="location">
                Paris, France <span class="dates">(Sept 2022 - June 2024)</span>
                </p>
            </header>
            <ul class="responsibilities">
                <li>Worked on a ROS2-based control system through Gazebo for French Cup of Robotics.</li>
            </ul>
        </section>

        <h2>üéì Education</h2>

        <section class="experience">
            <header>
                <h3>Master of Engineering ‚Äì Robotics</h3>
                <p class="location">
                Sorbonne University ‚Äì Paris, France <span class="dates">(2022 ‚Äì 2025)</span>
                </p>
            </header>
        </section>

        <section class="experience">
            <header>
                <h3>Master of Engineering ‚Äì Information Technology (Double Diploma)</h3>
                <p class="location">
                ETS Montr√©al ‚Äì Montr√©al, Canada <span class="dates">(2024 ‚Äì 2025)</span>
                </p>
            </header>
        </section>

        <h2>üìú Certifications</h2>

        <ul>
            <li>MIT - Machine Learning with Python (Dec 2023)</li>
            <li>NVIDIA - Learn OpenUSD: An Introduction (Nov 2024)</li>
        </ul>
    </div>

    <!-- Projects Section -->
    <div id="projects" class="section">
        <h1>Projects</h1>
        

        <h2>Kinova Gen3 RL & Sim2Real Toolkit</h2>
        <p>
            To enable Sim2Real deployment for the Kinova Gen3 robot, I set up a 
            modular pipeline using Isaac Lab‚Äôs extension system. The project 
            includes training scripts, pre-trained models, and ROS2 tools to 
            run RL policies directly on the real robot, without requiring Isaac 
            Lab or Isaac Sim at runtime. I've collaborated with the <a href="https://initrobots.ca/">INIT lab</a> 
            at √âTS Montr√©al to validate the full deployment on real 
            hardware.

            <a href="https://github.com/louislelay/kinova_isaaclab_sim2real" target="_blank">{GitHub Repo}</a>
        </p>

        <div class="image-gallery" data-project="kinova">
            <!-- Video as the first slide -->
            <iframe class="project-video" 
                    src="https://www.youtube.com/embed/5cP7AM1-FTA"
                    frameborder="0" allowfullscreen 
                    style="display: block;"></iframe>
            <iframe class="project-video" 
                    src="https://www.youtube.com/embed/zhHApKISTvw"
                    frameborder="0" allowfullscreen 
                    style="display: none;"></iframe>
            <iframe class="project-video" 
                    src="https://www.youtube.com/embed/PFjB_rF-dME"
                    frameborder="0" allowfullscreen 
                    style="display: none;"></iframe>
        
            <!-- Navigation buttons -->
            <button class="prev" onclick="plusSlides(-1, 'kinova')">Previous</button>
            <button class="next" onclick="plusSlides(1, 'kinova')">Next</button>
        </div>



        <h2>Disney BD-X Robot Locomotion Training</h2>
        <p>
            Developed a reinforcement learning environment for biped robot locomotion, 
            specifically for the BD-X robot from Disney Research, ensuring compatibility 
            with existing RL frameworks. The environment was designed and implemented with 
            a focus on efficient training and simulation, leading to its successful 
            integration into the IsaacLab repository. 

            <a href="https://github.com/isaac-sim/IsaacLab" target="_blank">{GitHub Repo}</a>
        </p>

        <iframe class="project-video" 
                src="https://www.youtube.com/embed/dT1HWIXhEPs" 
                frameborder="0" allowfullscreen 
                style="display: block;"></iframe>


        <h2>VR-Based Throwing Accuracy Study</h2>
        <p>
            Developed a VR simulation to study the impact of visual feedback 
            on throwing accuracy as part of a ball-throwing precision study. 
            The project aimed to investigate skill transfer through VR-based 
            training by building a detailed VR model and conducting experimental 
            analysis. The findings demonstrated the effectiveness of VR in skill 
            training, highlighting its potential for improving motor learning 
            and accuracy. 

            <a href="https://github.com/MPL-projects/vr-project" target="_blank">{GitHub Repo}</a>
        </p>

        <iframe class="project-video" 
                src="https://www.youtube.com/embed/TBcGD_-SzD4" 
                frameborder="0" allowfullscreen 
                style="display: block;"></iframe>

        <h2>Bipedal Wheeled Robot</h2>
        <p>
            Developed a wheeled bipedal robot in SolidWorks, focusing on an 
            innovative mechanism that eliminates cantilevering for enhanced 
            stability. After 3D printing the structure, I programmed it using 
            ROS2 for seamless locomotion control. The final design exhibits 
            high agility in diverse environments and demonstrates robust 
            motion capabilities.
        </p>

        <div class="image-gallery" data-project="bipedalWheeledRobot">
            <img class="project-image" 
                 src="media/BipedalWheeledRobot/robot-v3-irl.jpeg" 
                 alt="Robot v3 - IRL after 3D Printing" style="display:block;">
            <img class="project-image" 
                 src="media/BipedalWheeledRobot/robot-v3-cad.jpeg" 
                 alt="Robot v2 - Solidworks CAD" style="display:none;">
            <button class="prev" onclick="plusSlides(-1, 'bipedalWheeledRobot')">Previous</button>
            <button class="next" onclick="plusSlides(1, 'bipedalWheeledRobot')">Next</button>
        </div>
    
    
        <h2>Experimental Equipment for Orthostatic Exercise ‚Äì University of Tokyo</h2>
        <p>
            Developped code for a robotic assistive system to facilitate sit-to-stand motion 
            from a soft chair, primarily targeting elderly individuals. Using MATLAB for both 
            EMG-based intent detection and real-time seat hardening, the project reduced 
            muscle strain, as validated by camera and EMG analyses. 
            
            <a href="https://github.com/louislelay/Experimental-Equipment-for-Orthostatic-Exercise" target="_blank">{GitHub Repo}</a>
        </p>

        <div class="image-gallery" data-project="orthostaticExercise">
            <img class="project-image"
                 src="media/ExperimentalEquipmentForOrthostaticExercise/equipment.jpeg"
                 alt="Equipment" style="display:block;">
            <img class="project-image"
                 src="media/ExperimentalEquipmentForOrthostaticExercise/equipment-cad.png"
                 alt="CAD of the Equipment" style="display:none;">
            <img class="project-image"
                 src="media/ExperimentalEquipmentForOrthostaticExercise/equipment-plan.png"
                 alt="Plan of the Equipment" style="display:none;">
            <img class="project-image"
                 src="media/ExperimentalEquipmentForOrthostaticExercise/experiment.png"
                 alt="Experiment" style="display:none;">
            <button class="prev" onclick="plusSlides(-1, 'orthostaticExercise')">Previous</button>
            <button class="next" onclick="plusSlides(1, 'orthostaticExercise')">Next</button>
        </div>
    
    
        <h2>Semantic Sensor Fusion for Unitree Go1 ‚Äì University of Tokyo</h2>
        <p>
            Enhanced the Go1 quadruped robot‚Äôs perception by fusing LiDAR and 
            Realsense camera data via ROS, enabling a semantic mapping approach 
            using machine learning. This setup allows the robot to label and 
            interpret its surroundings, supporting tasks like person-following 
            and object-centric SLAM.  
        </p>

        <div class="image-gallery" data-project="semanticGo1">
            <img class="project-image"
                 src="media/SemanticSensorFusionGo1/WuJiaxuPoster-eng.png"
                 alt="Semantic Sensor Fusion Poster (translated to English)" style="display:block;">
            <img class="project-image"
                 src="media/SemanticSensorFusionGo1/fusion-rviz.png"
                 alt="Fusion of the 3D LiDAR and RGB-D data" style="display:none;">
            <img class="project-image"
                 src="media/SemanticSensorFusionGo1/WuJiaxuPoster-jp.jpeg"
                 alt="Semantic Sensor Fusion Poster (Japanese original version)" style="display:none;">
            <button class="prev" onclick="plusSlides(-1, 'semanticGo1')">Previous</button>
            <button class="next" onclick="plusSlides(1, 'semanticGo1')">Next</button>
        </div>
    
    
        <h2>Lane Detection and Vehicle Tracking ‚Äì Sorbonne University</h2>
        <p>
            Implemented a computer vision pipeline in C++ (OpenCV) that detects road lanes via 
            edge detection and Hough transforms, then identifies and counts vehicles using 
            bounding box tracking. The solution performs reliably under varying conditions, 
            demonstrating robust detection accuracy and efficient vehicle counting. 
            
            <a href="https://github.com/louislelay/Lane-Detection-and-Vehicle-Tracking" target="_blank">{GitHub Repo}</a>
        </p>

        <div class="image-gallery" data-project="laneDetection">
            <img class="project-image"
                 src="media/LaneDetectionAndVehicleTracking/count.jpeg"
                 alt="Counting the Vehicles" style="display:block;">
            <img class="project-image"
                 src="media/LaneDetectionAndVehicleTracking/steps.jpeg"
                 alt="Steps in Image Analysis" style="display:none;">
            <button class="prev" onclick="plusSlides(-1, 'laneDetection')">Previous</button>
            <button class="next" onclick="plusSlides(1, 'laneDetection')">Next</button>
        </div>
    
    
        <h2>8 DOF Quadruped Robot</h2>
        <p>
            Conceived a low-cost quadruped inspired by Boston Dynamics‚Äô SPOT and MIT‚Äôs Cheetah, 
            starting with a 3D-printed leg prototype driven by two servo motors and an Arduino. 
            The current setup lays groundwork for a full 12 DOF upgrade, with plans to 
            implement advanced leg control algorithms for more dynamic movement.
        </p>

        <div class="image-gallery" data-project="8DofQuadruped">
            <!-- Video as the first slide -->
            <iframe class="project-video" 
                    src="https://www.youtube.com/embed/jixDbttGpBg" 
                    frameborder="0" allowfullscreen 
                    style="display: block;"></iframe>
        
            <!-- Images -->
            <img class="project-image"
                 src="media/8DOFQuadruped/quadruped-cad.png"
                 alt="Quadruped Robot CAD - Prototype v1" 
                 style="display: none;">
                 
            <img class="project-image"
                 src="media/8DOFQuadruped/leg-cad.png"
                 alt="Quadruped Robot Leg CAD - Prototype v1" 
                 style="display: none;">
                 
            <img class="project-image"
                 src="media/8DOFQuadruped/leg-irl-1.jpeg"
                 alt="Quadruped Robot Leg - Prototype v1" 
                 style="display: none;">
                 
            <img class="project-image"
                 src="media/8DOFQuadruped/leg-irl-2.jpeg"
                 alt="Quadruped Robot Leg - Prototype v1" 
                 style="display: none;">
        
            <!-- Navigation buttons -->
            <button class="prev" onclick="plusSlides(-1, '8DofQuadruped')">Previous</button>
            <button class="next" onclick="plusSlides(1, '8DofQuadruped')">Next</button>
        </div>
        
    
        <h2>C++ Game ‚Äì Sorbonne University</h2>
        <p>
            Designed a minimalist 1v1 game on an 8√ó8 pixel grid entirely in C++, 
            supporting both keyboard and gamepad inputs without relying 
            on any external game engine. This project showcased core game-loop 
            coding, collision handling, and rendering logic in a compact yet 
            fully functional environment.  
            
            <a href="https://github.com/MPL-projects/POO-game" target="_blank">{GitHub Repo}</a>
        </p>

        <iframe class="project-video" src="https://www.youtube.com/embed/MueVXqSQhI4" frameborder="0" allowfullscreen style="display:block;"> </iframe>

    </div>

    <!-- Open Source Contributions -->
    <!-- </div> -->
    <div id="opensource" class="section">
        <h1>Open Source Contributions</h1>
        <p> &nbsp; </p>
        <h2>My GitHub Stats</h2>
        <p>&emsp;-&emsp;‚≠ê Total Stars Earned:&emsp;&emsp;&emsp;&nbsp;160+</p>
        <p>&emsp;-&emsp;‚è≥ Total commits (2025):&emsp;&emsp;&nbsp;700+</p>
        <p>&emsp;-&emsp;üéâ Total PRs:&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;70+</p>
        <p>&emsp;-&emsp;‚ö†Ô∏è Total Issues:&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;26</p>
        <p>&emsp;-&emsp;üîñ Contributed to (last year):&ensp;19</p>
        <p> &nbsp; </p>
        <h2>My recent contributions to open-source projects</h2>
        <div id="github-prs">Loading...</div>
        <div class="spacer"></div>
        <p> &nbsp; </p>
    </div>
    <!-- </div> -->



    <script>

        // window.addEventListener("load", () => {
        //     unifyAllGalleries(); // or unifyHeightsInGallery(...)
        // });


        function unifyAllGalleries() {
            // Grab all .image-gallery elements
            const allGalleries = document.querySelectorAll('.image-gallery');
            allGalleries.forEach(gallery => {
                unifyHeightsInGallery(gallery);
            });
        }

        function unifyHeightsInGallery(gallery) {
            const mediaElements = gallery.querySelectorAll('.project-image, .project-video');
            let maxHeight = 0;

            const loadPromises = Array.from(mediaElements).map(el => {
                return new Promise(resolve => {
                    if (el.tagName === 'IMG') {
                        if (el.complete) {
                            resolve();
                        } else {
                            el.onload = resolve;
                            el.onerror = resolve;
                        }
                    } else {
                        // For iframes, just resolve (can't load-detect easily)
                        resolve();
                    }
                });
            });

            Promise.all(loadPromises).then(() => {
                const galleryWidth = gallery.clientWidth;
                const targetWidth = galleryWidth * 0.5;

                mediaElements.forEach(el => {
                    let aspectRatio;

                    if (el.tagName === 'IMG') {
                        aspectRatio = el.naturalHeight / el.naturalWidth;
                    } else {
                        // Assume default 16:9 for iframe
                        aspectRatio = 9 / 16;
                    }

                    const thisDisplayedHeight = targetWidth * aspectRatio;

                    if (thisDisplayedHeight > maxHeight) {
                        maxHeight = thisDisplayedHeight;
                    }
                });

                mediaElements.forEach(el => {
                    el.style.width = targetWidth + 'px';
                    el.style.height = maxHeight + 'px';
                });
            });
        }


        // Basic slideshow logic for multiple projects
        function plusSlides(n, projectId) {

            const gallery = document.querySelector(`.image-gallery[data-project="${projectId}"]`);
            const slides = gallery.querySelectorAll('.project-image, .project-video');
            
            // Find current visible slide index
            let currentIndex = 0;
            for (let i = 0; i < slides.length; i++) {
                if (slides[i].style.display === 'block') {
                    currentIndex = i;
                    break;
                }
            }
    
            // Hide current slide
            slides[currentIndex].style.display = 'none';

            if (slides[currentIndex].tagName === 'IFRAME') {
                slides[currentIndex].src = slides[currentIndex].src;
            }
    
            // Calculate new index
            let newIndex = currentIndex + n;
            if (newIndex < 0) {
                newIndex = slides.length - 1;
            } else if (newIndex >= slides.length) {
                newIndex = 0;
            }
    
            // Show new slide
            slides[newIndex].style.display = 'block';


        }

        function showSection(id) {
            unifyAllGalleries();

            document.querySelectorAll('.section').forEach(section => {
                section.classList.remove('active');
            });
            document.getElementById(id).classList.add('active');
        }

        function toggleSidebar() {
            document.getElementById('sidebar').classList.toggle('show');
            adjustContentMargin();
        }

        function closeSidebar() {
            document.getElementById('sidebar').classList.remove('show');
            adjustContentMargin();
        }

        function adjustContentMargin() {
            if (window.innerWidth > 768) {
                document.getElementById('content').style.marginLeft = '25%';
            } else {
                document.getElementById('content').style.marginLeft = document.getElementById('sidebar').classList.contains('show') ? '25%' : '10%';
            }
        }

        window.addEventListener('resize', adjustContentMargin);

        async function fetchPullRequests() {
            let page = 1;
            let allPRs = [];

            // Loop until a page returns less than 100 items (indicating the last page)
            while (true) {
                const response = await fetch(`https://api.github.com/search/issues?q=author:louislelay+type:pr&per_page=100&page=${page}`);
                const data = await response.json();
                
                // If no items, break out of the loop
                if (!data.items || data.items.length === 0) break;
                
                allPRs = allPRs.concat(data.items);
                
                // If fewer than 100 items, then this is the last page.
                if (data.items.length < 100) break;
                
                page++;
            }

            const prContainer = document.getElementById('github-prs');
            prContainer.innerHTML = '';
            
            const groupedPRs = {};
            for (const pr of allPRs) {
                // Skip closed PRs that were not merged
                if (pr.state === 'closed' && !pr.pull_request.merged_at) continue;
                
                const date = new Date(pr.created_at).toLocaleDateString();
                const repoName = pr.repository_url.split('/').pop();
                const orgName = pr.repository_url.split('/')[4] || repoName;
                const status = pr.pull_request.merged_at ? 'Merged' : 'Pending';
                const repoLink = `https://github.com/${orgName}/${repoName}`;
                const prNumber = pr.html_url.split('/').pop();

                // Get repository data to fetch the star count
                const starsResponse = await fetch(`https://api.github.com/repos/${orgName}/${repoName}`);
                const repoData = await starsResponse.json();
                const stars = repoData.stargazers_count || 0;

                // ‚Üê‚Äî‚Äî only include repos with more than 10 stars
                if (stars <= 10) continue;

                if (!groupedPRs[date]) groupedPRs[date] = {};
                if (!groupedPRs[date][repoName]) {
                groupedPRs[date][repoName] = { orgName, repoLink, stars, prs: [] };
                }
                
                groupedPRs[date][repoName].prs.push({ title: pr.title, status, prNumber, prLink: pr.html_url });
            }
            
            // Render the grouped pull requests
            for (const [date, repos] of Object.entries(groupedPRs)) {
                prContainer.innerHTML += `<p class="date">${date}</p>`;
                for (const [repoName, repoData] of Object.entries(repos)) {
                prContainer.innerHTML += `<p class="repo">
                    <a href="${repoData.repoLink}" target="_blank">${repoData.orgName}/${repoName} (${repoData.stars}‚òÖ)</a>
                </p><ul>`;
                repoData.prs.forEach(pr => {
                    prContainer.innerHTML += `<li class="pr">${pr.status} - ${pr.title} 
                    <a href="${pr.prLink}" target="_blank">[#${pr.prNumber}]</a>
                    </li>`;
                });
                prContainer.innerHTML += `</ul>`;
                }
            }
        }

        fetchPullRequests();


    </script>
</body>
</html>
